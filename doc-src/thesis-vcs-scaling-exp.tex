\chapter{VCS Scaling Experiments}
\label{file-size-exp-desc}
\label{num-files-exp-desc}

We performed experiments to probe the limits of existing \acrlongpl{VCS}, to see
how they would cope with file sizes and file numbers in ranges beyond what would
be expected in a source code tree. We wanted to see how long it would take for
each \gls{VCS} to store that amount of data, how much disk space it used, and
what CPU utilization was like during storage. And since \glspl{VCS} track
changes, so we also wanted to see what would happen when a small subset of that
data was modified and then committed again.

We conducted two major experiments. To measure the effect of file size, we would
\gls{commit} a single file of increasing size to each target \gls{VCS}. And to
measure the effect of file numbers, we would \gls{commit} increasing number of
small (\SI{1}{\kibi\byte}) files to each target \gls{VCS}.



\section{Version Control Systems Evaluated}

We ran each experiment using five different \glspl{VCS}:

\begin{description}

    \item[Git] The most popular \glspl{DVCS}, and one of the main inspirations
        of \gls{DMV}. See \autoref{how-data-stored-in-git} for details about Git
        and how it stores data.

    \item[Mercurial] A \glspl{DVCS} that models data and history in the same
        manner as Git, but stores it differently. Rather than storing by hash
        object ID in an \gls{objectstore}, Mercurial creates a \gls{filelog} for
        each input file, storing its different versions as a base version
        followed by a series of deltas\cite[Chapter 4]{hgbook}.

    \item[Bup] A backup system that uses Git's data model and \gls{packfile}
        format. Like DMV, Bup breaks files into chunks using a
        \gls{rollinghash}. Unlike Git, it writes to the \gls{packfile} format
        directly, without Git's separate commit and pack steps, and without
        bothering to calculate deltas\cite{bup_design}. See
        \autoref{chunk-then-recombine} and \autoref{related_bup} for more
        discussion about Bup and its similarities and differences to DMV.

    \item[DMV] Our prototype system.

    \item[Copy] A control for the experiment, a dummy \gls{VCS} that simply
        copied the input files into another directory using the standard Unix
        \lstinline{cp} command.

\end{description}

The exact version of each \gls{VCS} used in the experiments is listed in
\autoref{vcs-versions}.

\begin{table}[bh]
    \caption{Version control systems evaluated and their versions}
    \label{vcs-versions}
    \centering
    \begin{tabular}{ l l }
        VCS & Version \\
        \midrule
        Git & 2.1.4 \\
        Mercurial & 3.1.2 \\
        Bup & debian/0.25-1 \\
        DMV & c9baf3a \\
        Copy (GNU \lstinline{cp}) & 8.23 \\
    \end{tabular}
\end{table}


\section{Procedure}

For each experiment, the procedure for a single trial was as follows:

\begin{tight_enumerate}

    \item Create an empty repository of the target \gls{VCS} in a temporary
        directory

    \item Generate target data to store, either a single file of the target
        size, or the target number of \SI{1}{\kibi\byte} files

    \item \Gls{commit} the target data to the repository, measuring wall clock
        time to \gls{commit}

    \item Verify that the first \gls{commit} exists in the repository, and if
        there was any kind of error, run the repository's integrity check
        operation

    \item Measure the total repository size

    \item Overwrite a fraction of each target file

    \item (Number-of-files experiment only) Run the \gls{VCS}'s status command
        that lists what files have changed, and measure the wall-clock time that
        it takes to complete

    \item \Gls{commit} again, measuring wall clock time to \gls{commit}

    \item Verify that the second \gls{commit} exists in the repository, and if
        there was any kind of error, run the repository's integrity check
        operation

    \item Measure the total repository size again

    \item (File-size experiment only) Run Git's garbage collector
        (\lstinline{git fsck}) to pack objects, then measure total repository
        size again

    \item Delete temporary directory and all trial files

\end{tight_enumerate}

We increased file sizes exponentially by powers of two from \SI{1}{\byte} up to
\SI{128}{\gibi\byte}, adding an additional step at \num{1.5} times the base size
at each order of magnitude. For example, starting at \SI{1}{\mebi\byte}, we
would run trails with \SI{1}{\mebi\byte}, \SI{1.5}{\mebi\byte},
\SI{2}{\mebi\byte}, \SI{3}{\mebi\byte}, \SI{4}{\mebi\byte}, \SI{6}{\mebi\byte},
\SI{8}{\mebi\byte}, \SI{12}{\mebi\byte}, and so on.

We increased numbers of files exponentially by powers of ten from one file to
ten million files, adding additional steps at \num{2.5}, \num{5}, and \num{7.5}
times the base number at each order of magnitude. For example, starting at
\num{100} files we would run trials with \num{100}, \num{250}, \num{500},
\num{750}, \num{1000}, \num{2500}, \num{5000}, \num{7500}, \num{10000}, and so
on.

Input data files consisted simply of pseudo-random bytes taken from the
operating system's pseudo-random number generator (\lstinline{/dev/urandom} on
Linux).

When updating data files for the second \gls{commit}, we would overwrite a
single contiguous section of each file with new pseudo-random bytes. We would
start one-quarter of the way into the file, and overwrite \num{1/1024}th of the
file's size (or 1 byte if the file was smaller than \SI{1024}{\kibi\byte}). So a
\SI{1}{\mebi\byte} file would have \SI{1}{\kibi\byte} overwritten, a
\SI{1}{\gibi\byte} file would have \SI{1}{\mebi\byte} overwritten, and so on.


\section{Automation and Measurement}

The trials were run via a Python script that would set up, run, and clean up
each trial in a loop, covering the full range of sizes or numbers for a given
\gls{VCS}. The script would measure the wall-clock time duration taken by each
\gls{commit} command and collect CPU utilization metrics. It would also
terminate any individual \gls{VCS} operation that ran longer than five and a
half hours. After \gls{commit} and verification, the script would also measure
repository size.

The script measured the wall-clock time duration for each \gls{commit} by
checking the system time (\lstinline{time.time()} in Python) just before and
just after using Python's \lstinline{subprocess} module to execute the necessary
\gls{VCS} command. CPU utilization was measured by sampling the CPU status lines
provided in Linux's \lstinline{/proc/stat} information. The status lines show a
cumulative count of CPU ticks (\num{1/100}{th} of a second) that the CPU has
spent in user mode, system mode, idle, and waiting for I/O\cite{proc_man_page}.
Like with the time measurements, the script samples CPU utilization before and
after executing a \gls{VCS} command, and then subtracts to get the number of
time slices spent in each state during execution. We then compare the relative
number of time slices in each state to get an idea of whether the operation is
CPU-bound or I/O-bound.

The script measures repository size using the standard Unix disk usage command
(\lstinline{du}) and measures the size of the trial's entire temporary
directory, which includes the generated input data itself along with the
\gls{VCS}'s storage.


\section{Experiment Platform}

We ran the trials on four dedicated computers with no other
load. Each was a typical office desktop with a \SI{3.16}{\giga\hertz}
\num{64}-bit dual-core processor and \SI{8}{\gibi\byte} of RAM, running Debian
version 8.6 ("Jessie"). Each computer had one normal SATA hard disk (spinning
platter, not solid-state), and trials were conducted on a dedicated
\SI{197}{\gibi\byte} LVM partition formatted with the ext4 filesystem. All came
from the same manufacturer with the same specifications and were, for practical purposes,
identical.
Additional details can be found in \autoref{test-machine-specs}.

\begin{table}
    \caption{Experiment computer specifications}
    \label{test-machine-specs}
    \begin{tabular}{ l l l }
        \multicolumn{3}{l}{Hardware} \\
        & Vendor & Hewlett Packard \\
        & CPU & Intel(R) Core(TM)2 Duo CPU     E8500  @ 3.16GHz \\
        & RAM & \SI{8}{\gibi\byte} \\
        & Hard disk & ATA model ST3250318AS \\
        \\
        \multicolumn{3}{l}{Operating system} \\
        & Operating system & Debian 8.6 ("Jessie") \\
        & Kernel & Linux 3.16.0 \\
        \\
        \multicolumn{3}{l}{Configuration} \\
        & Test partition & \SI{197}{\gibi\byte} LVM partition \\
        & Filesystem & ext4 \\
        & I/O scheduler & cfq (unless otherwise noted) \\
    \end{tabular}
\end{table}

We ran every trial four times, once on each of the experiment computers, and
took the mean and standard deviation of each time and disk space measurement.
However, because the experiment computers are practically identical, there was
little real variation.
