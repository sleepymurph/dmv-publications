\chapter{DMV Implementation}

We have written a \gls{DMV} prototype as a proof-of-concept. The \gls{DMV}
prototype is written in the Rust programming language and it runs from the Unix
command line, though it can also be compiled as a library to be used by other
applications.


\section{Command Line Control, Explicit operations}

Like with familiar \glspl{DVCS}, file changes in \gls{DMV} are explicitly
committed by user command. Synchronization is an explicit command as well.
Applications built on \gls{DMV} may add daemons to automatically \gls{commit}
and sync, but \gls{DMV} focuses only on providing the commands.

\gls{DMV} is used from the command line and includes familiar subcommands such
as branch, \gls{commit}, and checkout
(\autoref{prototype-help-output}\todo{Actually rename the prototype and
recapture output}).

\begin{figure}[h]
    \caption{DMV help output, listing subcommands}
    \label{prototype-help-output}
    \lstinputlisting[nolol,basicstyle=\scriptsize]{lst-prototype-help-output.txt}
\end{figure}



\section{Rust}

The implementation language, Rust, is a new C-like systems language that uses a
sophisticated type system to guarantee memory safety\todo{Cite Rust background},
avoiding data races in concurrent code, as well as the segmentation faults and
buffer overflows that are so easy to write in C. We chose Rust primarily because
it is a compiled language. Compiling to machine code gives us the best chance of
porting \gls{DMV} to low-powered or mobile devices\perotto{"(!)"}\askotto{"?"},
and it allows us to compile DMV as a library.



\section{Working Directory and Object Store}\label{dir-impl}

The \gls{DMV} prototype stores its objects as regular files on the file system,
using the same structure that Git does. The \gls{objectstore} is in a hidden
directory inside of the \gls{workdir} (\lstinline{.dmv/objects}). Objects are
stored using their SHA-1 hash as their filename, with the first two hex digits
removed to create a directory name (\autoref{dir-scheme-example}). This leads to
\num{256} subdirectories, each holding roughly \num{1/256}th of all the objects
stored. We experimented with other schemes to divide the objects
(\autoref{dir-experiment}), but we found that other schemes tended to create too
many subdirectories, exhausting the filesystem's available inodes before using
the available disk space.

\begin{figure}[h]
    \caption{Example object file name}
    \label{dir-scheme-example}
    \begin{tabular}{ l r }
        Object SHA-1 hash & \lstinline{c6e2f43ddee3c00041cdae8fedc3bd6961e61f69} \\
        Object file name & \lstinline{.dmv/objects/c6/e2f43ddee3c00041cdae8fedc3bd6961e61f69} \\
    \end{tabular}
\end{figure}

%


\section{Chunking algorithm}\label{chunking-algoritm}

Files are broken into chunks using the same \glsfirst{rollinghash} used by Gzip
and Rsyncrypto\cite{rsyncrypto_algorithm} to respectively compress and encrypt
files by chunks so that the result is "rsyncable"-- a remote copy of the
compressed or encrypted file can be updated by transferring only those chunks
that have changed.

The algorithm keeps a sum of the previous \num{8196} bytes of input data, and
creates a chunk boundary when that sum is evenly divisible by \num{4096}. These
parameters are arbitrary and can be adjusted. Let \glssymbol{windowsize} denote
the \gls{windowsize}, the number of previous bytes summed, and let
\glssymbol{divisor} denote the \gls{divisor} of the modulus operation. Also, let
$P_n$ denote the \gls{rollinghash} sum for position $n$ of the input stream.
Then a chunk boundary is where

\begin{equation}
    P_n = \left( \sum_{i = n - w }^{n}{P_i} \right) \bmod d = 0
\end{equation}

In experiments with our implementation of this \glsfirst{rollinghash}
(\autoref{rolling-hash-exp}), Rsyncrypto's parameters with a \gls{windowsize} of
\SI{8192}{\byte} and a divisor of \num{4096} yielded a mean chunk size of
\SI{4.1}{\kib} with a standard deviation of \SI{4.6}{\kib}. We adjusted the
parameters for DMV to a \gls{windowsize} of \SI{32}{\kib} and a divisor of
\SI{16}{\kibi\relax}, which yielded a mean chunk size of \SI{18.7}{\kib} with a
standard deviation of \SI{22.0}{\kib}. These larger chunk sizes resulted in
faster commit times for large files in our experiments
(\autoref{rolling-hash-exp}).

%     8192   4096     4213.8     4738.0 0.156
%    32768  16384    19169.9    22486.4 0.697
