\section{Results}

\subsection{File Size}

\subsubsection{File Size Limits}

\written{We find that processing files whole will limit maximum file size to what can fit in RAM.}

In our experiments, both Git and Mercurial had file size limits that were related to RAM.
Mercurial would refuse to commit a file \SI{2}{\gib} or larger.
It would exit with an error code and print an error message saying "up to 6442 MB of RAM may be required to manage this file."
The commit would not be stored, and the repository would be left unchanged.
This suggests that Mercurial needs to be able to fit the file into memory three times over in order to commit it.

Git's commit operation would appear to fail with files \SI{12}{\gib} and larger.
It would exit with an error code and print an error message saying "fatal: Out of memory, malloc failed (tried to allocate 12884901889 bytes)."
However, the commit would be written to the repository, and git's \lstinline{fsck} operation would report no errors.
So the commit operation completes successfully, even though an error is reported.

With files \SI{24}{\gib} and larger, Git's \lstinline{fsck} operation itself would fail.
The \lstinline{fsck} command would exit with an error code and give a similar "fatal ... malloc" error.
However, the file could still be checked out from the repository without error.
So we continued the trials assuming that these were also false alarms.

These findings are summarized in \autoref{file-sizes-table} and
\autoref{vcs-size-limits-table}.

\begin{table}[]
    \caption{Observations as file size increases}
    \label{file-sizes-table}
    \centering
    \begin{tabular}{r l}
        Size & Observation \\
        \midrule
        \SI{1.5}{\gibi\byte} & Largest successful commit with Mercurial \\
        \SI{2}{\gibi\byte} & Mercurial commit rejected \\
        \SI{8}{\gibi\byte} & Largest successful commit with Git \\
        \SI{12}{\gibi\byte} & Git false-alarm errors begin, but commit still intact \\
        \SI{16}{\gibi\byte} & Largest successful Git fsck command \\
        \SI{24}{\gibi\byte} & Git false-alarm errors begin during fsck, but commit still intact \\
        \SI{64}{\gibi\byte} & Largest successful DMV commit \\
        \SI{96}{\gibi\byte} & DMV timeout after \SI{5.5}{\hour} \\
        \SI{96}{\gibi\byte} & Last successful commit with Bup (and Git, ignoring false-alarm errors) \\
        \SI{128}{\gibi\byte} & All fail due to size of test partition \\
    \end{tabular}
\end{table}

\begin{table}[]
    \caption{Effective size limits for VCSs evaluated}
    \label{vcs-size-limits-table}
    \centering
    \begin{tabular}{l l}

        VCS & Effective limit \\
        \midrule

        Git & Commit intact at all sizes, UI reports errors at \SI{12}{\gibi\byte} and larger \\

        Mercurial & Commit rejected at \SI{2}{\gibi\byte} and larger \\

        Bup & Successful commits at all sizes tried, up to \SI{96}{\gibi\byte} \\

        DMV & Successful commits up to \SI{64}{\gibi\byte}, timeout at
        \SI{5.5}{\hour} during \SI{96}{\gibi\byte} trial

    \end{tabular}
\end{table}

%


\towrite{Give file size result timing}

\subsection{Number of Files}

\towrite{And we find that storing millions of objects loose as files with hash-based names will result in inefficient write speeds and use of disk space.}
