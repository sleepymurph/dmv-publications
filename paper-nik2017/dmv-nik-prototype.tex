\section{Distributed Media Versioning}

\written{We developed an early prototype of such a system, which we call Distributed Media Versioning (DMV).}

\todo[inline]{Reduce and compress the DMV section}

Git's \gls{DAG} data structure has several interesting properties for distributed data storage.

\begin{description}

    \item[De-duplication]
        Identical objects are de-duplicated because they will have the same ID and naturally collapse into a single object in the data store.
        This results in a natural compression of redundant objects.

    \item[A record of causality]
        Copies of the DAG can be distributed and updated independently.
        Concurrent updates will result in multiple branches of history, but references from child commit to parent commit establish a happens-before relationship and give a chain of causality.
        Branches can be merged by manually reconciling the changes, and then creating a merge commit that refers to both parent commits.
        When transferring updates from one copy to another, only new objects need to be transferred.

    \item[Atomic updates]
        When a new commit is added, all objects are added the database first, then finally the reference to the current commit is updated.
        This reference is a 160-byte SHA-1 hash value, and which can be updated atomically.

    \item[Verifiability]
        Because every object is identified by its cryptographic hash, the data integrity of each object can be verified at any time by re-computing and checking its hash.
        And because objects refer to other objects by hash, the graph is a form of blockchain.
        All objects can be verified by checking hashes and following references from the most recent commits down to the initial commits and the blob leaves of the graph.

\end{description}

The efficiency of de-duplication depends on how well identical pieces of data map to identical objects.
In Git, the redundant objects are the files and directories that do not change between commits.
De-duplication of redundant data within files is accomplished by aggregating objects together into pack files and compressing them with zlib \cite[Section 10.4]{git_book}.

Calculating deltas during this \glsdisp{packfile}{packing} phase requires loading the objects into memory, and so it can cause an out-of-memory error if an object is too large to fit into available RAM.
Because Git stores files whole in \glspl{blob}, it cannot \glsdisp{packfile}{pack} objects that are larger than available RAM.

If the \gls{DAG} operated at a granularity smaller than the file, it could become even more powerful.
It could naturally de-duplicate chunks of files the way that Git already de-duplicates whole files, and it could ensure that all objects fit into RAM for \glsdisp{packfile}{packing} or other operations.

This sub-file granularity and de-duplication is the core idea behind our new data storage system, \acrlong{DMV}.

%

\glsreset{DMV}

\gls{DMV} is our new distributed data storage platform.
The core idea is relatively simple --- store data in a Git-like \gls{DAG}, but make the following changes:

\begin{tight_enumerate}

    \item{Store data at a finer granularity than the file}

    \item{Allow nodes to store only a portion of the \gls{DAG} as a whole}

\end{tight_enumerate}

Doing so allows a data set to be replicated or sharded across many nodes according to the capacity of nodes and the needs of local users.
The focus is on data locality: tracking what data is where, presenting that information to the user, and making it easy to transfer data to other nodes as desired.
The ultimate goal is to create a new abstraction, of \emph{many devices, one data item} in varying states of synchronization.

%

\gls{DMV}'s data set and its history are represented as a \acrshort{DAG} (\acrlong{DAG}, see \autoref{how-data-stored-in-git}), and the rest of the design flows from that.
\gls{DMV}'s \gls{DAG} is based on Git's, but it adds a new object type, the \gls{chunkedblob}, which represents a \gls{blob} that has been broken into several smaller chunks.
An example \gls{DMV} \gls{DAG} is shown in \autoref{dia_dmv_dag_example_three_commits}.


Files are split into chunks using a \gls{rollinghash} such as Rabin-Karp fingerprinting~\cite{rabin_karp_fingerprinting}.
\todo{It's the rsync algorithm}
This splits the files into chunks by content rather than position, so that identical chunks within files (and especially different versions of the same file) will be found and stored as identical objects, regardless of their position within the file.
This way, identical chunks will be naturally de-duplicated by the \gls{DAG}, and only the changed portions of files need to be stored as new objects.


\begin{figure}[]
    \centering

    \begin{minipage}{.65\textwidth}
        \includegraphics[width=\textwidth]{dia_dmv_dag_example_three_commits}
        \caption{A simple DMV DAG with three commits}
        \label{dia_dmv_dag_example_three_commits}
    \end{minipage}%
    \begin{minipage}{.35\textwidth}
        \includegraphics[width=\textwidth]{dia_new_dag}
        \caption{DMV DAG Object Types}
        \label{fig:dia_new_dag}
    \end{minipage}
\end{figure}


We have written a \gls{DMV} prototype as a proof-of-concept. The \gls{DMV}
prototype is written in the Rust programming language and it runs from the Unix
command line, with the executable built as a thin wrapper around a library, so
that it can be used by other applications.

The \gls{DMV} prototype was developed with Rust stable versions 1.15 and 1.16 on
Debian Linux 8.6 ("Jessie"). The current DMV prototype stands at \num{7592}
lines of Rust code (\num{6565} excluding comments). Source code is available
alongside this dissertation in Munin, the University of Troms√∏'s open research
archive (\muninurl), and continued work can be found via the author's website
(\dmvurl).
