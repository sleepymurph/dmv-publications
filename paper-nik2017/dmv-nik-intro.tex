\section{Introduction}

\written{Distributed version control is an interesting form of distributed system because it takes eventual consistency to the extreme.}

Distributed systems are ruled by the \gls{CAP-theorem}~\cite{cap_origin}, which states that a system cannot be completely consistent (C), available (A), and tolerant of network partitions (P) all at the same time.
When communication between replicas breaks down and they cannot all acknowledge an operation, the system is faced with "the \gls{partitiondecision}: block the operation and thus decrease availability, or proceed and thus risk inconsistency."~\cite{cap_years_later}

Much research is aimed at improving consistency.
Vector clocks~\cite{lamport_ordering} and consensus algorithms such as Paxos~\cite{paxos_made_simple,paxos_made_moderately_complex} make sure the same updates are applied in the same order on all replicas even, if a minority of nodes cannot respond.
There are also data types are cleverly designed to be commutative, so that the resulting data will be the same regardless of the order in which updates are applied~\cite{crdt_orig}.
But in general, when systems cannot communicate, the CAP theorem cannot be avoided~\cite{cap_proof}, and the system is still faced with the \gls{partitiondecision}.

\written{Every replica of a repository contains the full history in an append-only data structure, any replica may add new commits, and conflicting updates are reconciled later in a merge operation.}

Though maybe not designed with the CAP theorem explicitly in mind, a \gls{DVCS} is in fact a small-scale distributed system that takes the availability-first approach to the extreme.
Rather than a set of connected nodes that may occasionally lose contact in a network partition, a \gls{DVCS}'s \glspl{repository} are self-contained and offline by default.
They allow writes to local data at any time, and only connect to other \glspl{repository} intermittently by user command to exchange updates.
Concurrent updates are not only allowed but embraced as different \glspl{branch} of development.
A \gls{DVCS} can track many different \glspl{branch} at the same time, and conflicting \glspl{branch} can be combined and resolved by the user in a \gls{merge} operation.

The \glsdisp{DVCS}{distributed version control} concept may have something to
teach larger-scale systems about availability.

\written{These systems are popular, but their use is generally limited to the small text files of source code.}

\Glspl{DVCS} are designed primarily to store program source code: plain text files in the range of tens of kilobytes.
Checking in larger binary files such as images, sound, or video affects performance.
Actions that require copying data in and out of the system slow from hundredths of a second to full seconds or minutes.
And since a \gls{DVCS} keeps every version of every file in every \gls{repository}, forever, the disk space needs compound.

This has lead to a conventional wisdom that binary files should never be stored in version control, inspiring blog posts with titles such as
"Don't ever commit binary files to Git! Or what to do if you do"~\cite{dont_ever_commit_binaries_to_version_control},
even as the modern software development practice of continuous delivery was commanding teams to "keep absolutely everything in version control."~\cite[p.33]{continuousdeliverybook}

\towrite{This paper explores the challenges of using version control to store larger binary files, with the goal of building a scalable, highly-available, distributed storage system for media files such as images, audio, and video.}

\subsection{The Power of the DAG}

Git stores data in a directed acyclic graph (DAG) data structure~\cite{git_initial_readme}.
Each version of each file is hashed with the cryptographic SHA-1 digest, becoming a blob object, which is stored in an object store with the SHA-1 hash as its ID.
Directory states are stored by creating a list of hash IDs for each file in the directory, a tree object, and also storing it by SHA-1 hash ID.
Tree objects can also refer to other trees, representing subdirectories.
Commit objects contain the hash ID of the tree object representing the directory state at the time of commit, plus metadata such as the author and commit message.
The resulting graph is directed because the links between objects are directional.
It is acyclic because objects are content-addressed.
An object can only refer to another object by hash, so it must refer to an existing object whose hash is known.
And objects cannot be updated without changing their hash.
Therefore, it is impossible to create a circular reference.

This DAG data structure has several interesting properties for distributed data storage.
The content-addressing naturally de-duplicates identical objects, since identical objects will have the same hash ID.
This results in a natural compression of redundant objects.
The append-only nature of the DAG allows replicas to make independent updates without disturbing the existing history.
Then, when transferring updates from one replica to another, only new objects need to be transferred.
Concurrent updates will result in multiple branches of history, but references from child commit to parent commit establish a happens-before relationship and give a chain of causality.
Data integrity can also be verified by re-hashing each object and comparing to its ID, protecting against tampering and bit rot.
Updates can also be made atomic by waiting to update branch head references until after all new objects are written to the object store.

The efficiency of de-duplication depends on how well identical pieces of data map to identical objects.
In Git, the redundant objects are the files and directories that do not change between commits.
De-duplication of redundant data within files is accomplished by aggregating objects together into pack files and compressing them with zlib \cite[Section 10.4]{git_book}.

Calculating deltas during this \glsdisp{packfile}{packing} phase requires loading the objects into memory, and so it can cause an out-of-memory error if an object is too large to fit into available RAM.
Because Git stores files whole in \glspl{blob}, it cannot \glsdisp{packfile}{pack} objects that are larger than available RAM.

If the \gls{DAG} operated at a granularity smaller than the file, it could become even more powerful.
It could naturally de-duplicate chunks of files the way that Git already de-duplicates whole files, and it could ensure that all objects fit into RAM for \glsdisp{packfile}{packing} or other operations.

This sub-file granularity and de-duplication is the core idea behind our new data storage system, \acrlong{DMV}.

%
